package unvsef

import (
	"database/sql"
	"encoding/json"
	"errors"
	"fmt"
	"reflect"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"
	"unicode"
	"unsafe"

	"github.com/jinzhu/inflection"
)

type DBType string

const (
	DBPostgres  DBType = "postgres"
	DBMySQL     DBType = "mysql"
	DBMariaDB   DBType = "mariadb"
	DBMSSQL     DBType = "sqlserver"
	DBSQLite    DBType = "sqlite"
	DBOracle    DBType = "oracle"
	DBTiDB      DBType = "tidb"
	DBCockroach DBType = "cockroach"
	DBGreenplum DBType = "greenplum"
	DBUnknown   DBType = "unknown"
)

// --------------------- Tag Metadata ---------------------
// FieldTag holds parsed metadata from struct field tags.
type FieldTag struct {
	PrimaryKey    bool
	AutoIncrement bool
	Unique        bool
	/*
		can be field name if no unique index name in tag else name of unique index in tag
	*/
	UniqueName string
	Index      bool
	/*
		can be field name if no  index name in tag else name of  index in tag
	*/
	IndexName string
	Length    *int
	FTSName   string
	DBType    string
	TableName string
	Check     string
	Nullable  bool
	Field     reflect.StructField
	Default   string
}
type utilsPackage struct {
	cacheGetMetaInfo                        sync.Map
	CacheTableNameFromStruct                sync.Map
	cacheGetPkFromMeta                      sync.Map
	cacheGetUniqueConstraintsFromMetaByType sync.Map
	cacheGetIndexConstraintsFromMetaByType  sync.Map
	schemaCache                             sync.Map
	cacheGetOrCreateRepository              sync.Map
	cacheGetTenantDb                        sync.Map
	cacheBuildFieldMap                      sync.Map
	mapType                                 map[reflect.Type]string
	currentPackagePath                      string //<-- cache current package path
	cacheGetRequireFields                   sync.Map
	cacheGetAutoPkKey                       sync.Map
}

// ParseDBTag parses the `db` struct tag into a FieldTag struct.
func (u *utilsPackage) ParseDBTag(field reflect.StructField) FieldTag {

	tag := strings.TrimSpace(field.Tag.Get("db"))
	t := FieldTag{
		Field: field,
	}

	t.Nullable = field.Type.Kind() == reflect.Ptr
	tag = strings.TrimSpace(tag)
	if tag == "" {
		return t
	}
	parts := strings.Split(tag, ";")
	for _, p := range parts {
		p = strings.TrimSpace(p)
		switch {

		case p == "primaryKey":
			t.PrimaryKey = true
		case p == "autoIncrement":
			t.AutoIncrement = true
		case p == "unique":
			t.Unique = true
			t.UniqueName = u.ToSnakeCase(field.Name)
		case strings.HasPrefix(p, "unique("):
			t.Unique = true
			t.UniqueName = u.extractName(p)
		case p == "index":
			t.Index = true
			t.IndexName = u.ToSnakeCase(field.Name)
		case strings.HasPrefix(p, "index("):
			t.Index = true
			t.IndexName = u.extractName(p)
		case strings.HasPrefix(p, "table("):
			t.TableName = u.extractName(p)
		case strings.HasPrefix(p, "length("):
			if s := u.extractName(p); s != "" {
				if n, err := strconv.Atoi(s); err == nil {
					t.Length = &n
				}
			}
		case strings.HasPrefix(p, "check("):
			t.Check = u.extractName(p)

			if s := u.extractName(p); s != "" {
				if n, err := strconv.Atoi(s); err == nil {
					t.Length = &n
				}
			}
		case strings.HasPrefix(p, "FTS("):
			t.FTSName = u.extractName(p)
		case strings.HasPrefix(p, "type:"):
			t.DBType = strings.TrimPrefix(p, "type:")
		case strings.HasPrefix(p, "default:"):
			t.Default = strings.TrimPrefix(p, "default:")
		}

	}
	return t
}

func (u *utilsPackage) extractName(s string) string {
	re := regexp.MustCompile(`\((.*?)\)`)
	matches := re.FindStringSubmatch(s)
	if len(matches) == 2 {
		return matches[1]
	}
	return ""
}
func (u *utilsPackage) Contains(list []string, item string) bool {
	item = strings.ToLower(item)
	for _, v := range list {
		if strings.ToLower(v) == item {
			return true
		}
	}
	return false
}
func (u *utilsPackage) ToSnakeCase(str string) string {
	var result []rune
	for i, r := range str {
		if i > 0 && unicode.IsUpper(r) &&
			(unicode.IsLower(rune(str[i-1])) || (i+1 < len(str) && unicode.IsLower(rune(str[i+1])))) {
			result = append(result, '_')
		}
		result = append(result, unicode.ToLower(r))
	}
	return string(result)
}

/*
Get table name from struct

	 Example :

	 type User struct {
		  _ DbField[any] `db:table(my_user)`

	 }

	 return my_user

	 type User struct {} -> "users"
*/
func (u *utilsPackage) TableNameFromStruct(typ reflect.Type) string {
	// Check for override via table(...) tag
	if v, ok := u.CacheTableNameFromStruct.Load(typ); ok {
		return v.(string)
	}
	for i := 0; i < typ.NumField(); i++ {
		if typ.Field(i).Name == "_" {
			parsed := u.ParseDBTag(typ.Field(i))
			if parsed.TableName != "" {
				return parsed.TableName
			}
		}
	}
	base := u.ToSnakeCase(typ.Name())
	ret := inflection.Plural(base)
	u.CacheTableNameFromStruct.Store(typ, ret)
	return ret
}

/*
	   Get Go type of DbField in name

	   Example:
	    var testType= DbField[time.Time]{}
		utils.ResolveFieldKind(reflect.TypeOf(&testType))-> "time.Time"
*/
func (u *utilsPackage) ResolveFieldKind(field reflect.StructField) string {

	ftType := field.Type
	if ftType.Kind() == reflect.Ptr {
		ftType = ftType.Elem()
	}

	if ftType.PkgPath() == u.currentPackagePath {

		if ftType.Kind() == reflect.Ptr {
			ftType = ftType.Elem()
		}
		if typeName, ok := u.mapType[ftType]; ok {
			return typeName
		} else {
			panic(fmt.Errorf("'utilsPackage.ResolveFieldKind (row 204)' report: %s was not found in mapType of utilsPackage", ftType.String()))
		}
	}
	strFt := field.Type.String()
	if strings.Contains(strFt, ".DbField[") {
		typeParam := strings.Split(strFt, ".DbField[")[1]
		typeParam = strings.Split(typeParam, "]")[0]
		typeParam = strings.TrimLeft(typeParam, "*")
		return typeParam
	}
	return field.Type.Kind().String()
}

/*
Extract all info of reflect.Type
After fetch all info in reflect.Type the meta info will be cache
Next call will get from cache instead of fetch again

# Example 1:

	type User struct {
			_ DbField[any] `db:"table(MyUser)"` //<-- Optional
			Id   DbField[uint64] `db:"primaryKey;autoIncrement"`
			Code DbField[string] `db:"unique;length(50)"`
			Name DbField[string] `db:"index;length(50)"`
		}

		return map {
				users: {
					id:{
						PrimaryKey    : true
					},
					code: {
							Unique:true,
							UniqueName: code_uk
					},
					name: {
							Index: true,
							IndexName; name_uk
					}
				}
		}
		# Exmaple 2
		type struct UserRole {
			Id   DbField[uint64]     `db:"primaryKey;autoIncrement"`
			UserId  DbField[uint64]  `db:"unique(user_role)"` //<-- unique constraint 2 columns
			RoleId  DbField[uint64]  `db:"unique(user_role)"` //<-- unique constraint 2 columns
		}
		return
		{
			users: {
				id: {
					PrimaryKey: true
				},
				user_id: {
					Unique: true,
					UniqueName: user_role_uk
				},
				role_id: {
					Unique: true,
					UniqueName: user_role_uk
				}
			}
		}
*/
func (u *utilsPackage) GetMetaInfo(typ reflect.Type) map[string]map[string]FieldTag {
	// 1. Kiểm tra cache trước (check cache first)
	if metaInfo, ok := u.cacheGetMetaInfo.Load(typ); ok {
		return metaInfo.(map[string]map[string]FieldTag)
	}

	// 2. Tạo mới metadata
	metaInfo := make(map[string]map[string]FieldTag)
	tableName := utils.TableNameFromStruct(typ)
	for i := 0; i < typ.NumField(); i++ {
		field := typ.Field(i)

		// Bỏ qua field đặc biệt "_" (used for table(...) override)
		if field.Name == "_" {

			continue
		}

		// 3. Nếu là embedded struct (anonymous), đệ quy lấy metadata của nó
		if field.Anonymous {
			embeddedMeta := u.GetMetaInfo(field.Type)
			for tableName, fields := range embeddedMeta {
				if _, ok := metaInfo[tableName]; !ok {
					metaInfo[tableName] = make(map[string]FieldTag)
				}
				for fieldName, fieldTag := range fields {

					metaInfo[tableName][u.ToSnakeCase(fieldName)] = fieldTag
				}
			}
			continue
		}

		if _, ok := metaInfo[tableName]; !ok {
			metaInfo[tableName] = make(map[string]FieldTag)
		}

		// 5. Gán tag metadata cho field
		metaInfo[tableName][u.ToSnakeCase(field.Name)] = u.ParseDBTag(field)
	}

	// 6. Cache lại và trả về
	u.cacheGetMetaInfo.Store(typ, metaInfo)
	return metaInfo
}

/*
The purpose support for Dialects is to provide a way to customize the SQL generation for different databases.
*/
func (u *utilsPackage) Quote(strQuote string, str ...string) string {
	left := strQuote[0:1]
	right := strQuote[1:2]
	ret := left + strings.Join(str, left+"."+right) + right
	return ret
}

/*
The function will get all primary key cols from type (the  info will be stored in cache . The next call will return form cache)
return

	{
		"<primary key constraint name": {//<-- The value is obtained by the combination of the table name, double underscores ("__"), and the column name.
			"<key field name 1>": {...},//<--FieldTag Info
			...
			"<key field name n>": {...},//<--FieldTag Info
		}
	}
*/
func (u *utilsPackage) GetPkFromMetaByType(typ reflect.Type) map[string]map[string]FieldTag {
	// 1. Kiểm tra cache trước (check cache first)
	if pk, ok := u.cacheGetPkFromMeta.Load(typ); ok {
		return pk.(map[string]map[string]FieldTag)
	}
	metaInfo := u.GetMetaInfo(typ)
	ret := make(map[string]map[string]FieldTag)
	fieldsNames := []string{}
	for tableName, fields := range metaInfo {
		pkMap := make(map[string]FieldTag)
		for fieldName, fieldTag := range fields {
			if fieldTag.PrimaryKey {
				pkMap[fieldName] = fieldTag
				fieldsNames = append(fieldsNames, fieldName)

			}
		}
		ret[tableName+"_"+strings.Join(fieldsNames, "_")] = pkMap

	}
	u.cacheGetPkFromMeta.Store(typ, ret)
	return ret
}

/*
The method will get all Unique Constraint from declarification type
#Exmaple

	type struct UserRole {
			Id   DbField[uint64]     `db:"primaryKey;autoIncrement"`
			UserId  DbField[uint64]  `db:"unique(user_role_idx)"` //<-- unique constraint 2 columns
			RoleId  DbField[uint64]  `db:"unique(user_role_idx)"` //<-- unique constraint 2 columns
			OwnerId DbField[uint64] `db:"unique"` //<-- unique constraint 1 column
	}

	return {
		"user_roles":{ //<-- table name
			"user_role_idx____user_roles___user_id__role_id":{ //<--- convention of constraint name is the combination of constraint name in tag, four underscores and table name (snake case)
				"user_id": {...} //<-- col 1
				"role_id": {...} // <--col 2
			},
			"user_role_idx____user_roles__owner_id": { //<--- convention of constraint name is the combination of field name (snake case) four underscore and table name (snake case)
				"owner_id": {...} //<-- field name
			}

		}
	}
*/
func (u *utilsPackage) GetUniqueConstraintsFromMetaByType(typ reflect.Type) map[string]map[string]FieldTag {
	// 1. Kiểm tra cache trước (check cache first)
	if unique, ok := u.cacheGetUniqueConstraintsFromMetaByType.Load(typ); ok {
		return unique.(map[string]map[string]FieldTag)
	}
	metaInfo := u.GetMetaInfo(typ)
	info := make(map[string]map[string]FieldTag)
	tableName := u.TableNameFromStruct(typ)

	for _, fields := range metaInfo {
		for fieldName, fieldTag := range fields {

			if fieldTag.Unique {
				ukName := fieldTag.UniqueName //<-- use fieldTag.UniqueName can be field name if no unique index name in tag else name of unique index in tag
				if _, ok := info[ukName]; !ok {
					info[ukName] = make(map[string]FieldTag)

				}
				info[ukName][fieldName] = fieldTag

			}
		}
	}
	ret := make(map[string]map[string]FieldTag)
	for ukName, fields := range info {

		refFields := []string{}
		for fieldName := range fields {
			refFields = append(refFields, fieldName)
		}
		constraintName := ukName + "____" + tableName + "___" + strings.Join(refFields, "__")
		ret[constraintName] = fields
	}
	u.cacheGetUniqueConstraintsFromMetaByType.Store(typ, ret)
	return ret
}

/*
The method will get all Unique Constraint from declarification type
#Exmaple

	type struct UserRole {
			Id   DbField[uint64]     `db:"primaryKey;autoIncrement"`
			UserId  DbField[uint64]  `db:"index(user_role_idx)"` //<-- unique constraint 2 columns
			RoleId  DbField[uint64]  `db:"index(user_role_idx)"` //<-- unique constraint 2 columns
			OwnerId DbField[uint64] `db:"index"` //<-- unique constraint 1 column
	}

	return {
		"user_roles":{ //<-- table name
			"user_role_idx____user_roles":{ //<--- convention of constraint name is constraint name in tag +"___"+ table name
				"user_id": {...} //<-- col 1
				"role_id": {...} // <--col 2
			},
			"user_roles____owner_id_idx": { //<--- constraint name
				"owner_id": {...} //<-- field name
			}

		}
	}
*/
func (u *utilsPackage) GetIndexConstraintsFromMetaByType(typ reflect.Type) map[string]map[string]FieldTag {
	// 1. Kiểm tra cache trước (check cache first)
	if unique, ok := u.cacheGetIndexConstraintsFromMetaByType.Load(typ); ok {
		return unique.(map[string]map[string]FieldTag)
	}
	metaInfo := u.GetMetaInfo(typ)
	info := make(map[string]map[string]FieldTag)
	tableName := u.TableNameFromStruct(typ)

	for _, fields := range metaInfo {
		for fieldName, fieldTag := range fields {

			if fieldTag.Index {
				indexName := fieldTag.IndexName
				if _, ok := info[indexName]; !ok {
					info[indexName] = make(map[string]FieldTag)

				}
				info[indexName][fieldName] = fieldTag

			}
		}
	}
	ret := make(map[string]map[string]FieldTag)
	for idxName, fields := range info {

		refFields := []string{}
		for fieldName := range fields {
			refFields = append(refFields, fieldName)
		}
		constraintName := idxName + "____" + tableName + "___" + strings.Join(refFields, "__")
		ret[constraintName] = fields
	}
	u.cacheGetIndexConstraintsFromMetaByType.Store(typ, ret)
	return ret
}

type fkInfo struct {
	FromTable string
	FromField []string
	ToTable   string
	ToField   []string
}

type schemaMap struct {
	table  map[string]bool
	unique map[string]bool
	index  map[string]bool
	fk     map[string]bool
}

func (u *utilsPackage) extractSchema(db *sql.DB, dbName string, dialect Dialect) (*schemaMap, error) {

	dialect.RefreshSchemaCache(db, dbName)
	schema, err := dialect.GetSchema(db, dbName)
	if err != nil {
		return nil, err
	}
	ret := &schemaMap{
		table:  make(map[string]bool),
		unique: make(map[string]bool),
		index:  make(map[string]bool),
		fk:     make(map[string]bool),
	}
	for tableName, table := range schema {
		ret.table[tableName] = true

		for _, constraintName := range table.UniqueConstraints {
			ret.unique[constraintName] = true
		}
		for _, constraintName := range table.IndexConstraints {
			ret.index[constraintName] = true
		}
	}
	u.schemaCache.Store(dbName, ret)
	return ret, nil

}

func (u *utilsPackage) GetScriptMigrate(db *sql.DB, dbName string, dialect Dialect, typ ...reflect.Type) ([]string, error) {
	dbSchema, err := utils.extractSchema(db, dbName, dialect)
	if err != nil {
		return nil, err
	}

	ret := []string{}
	for _, t := range typ {
		sqlCmds, err := dialect.GenerateCreateTableSql(dbName, t)
		if err != nil {
			return nil, err
		}
		if sqlCmds != "" {
			ret = append(ret, sqlCmds)
		} else { //<--- table is existing in Database, just add columns
			sqlAddCols, err := dialect.GenerateAlterTableSql(dbName, t)
			if err != nil {
				return nil, err
			}
			ret = append(ret, sqlAddCols...)
		}
		sqlUniqueConstraints := dialect.GenerateUniqueConstraintsSql(t)

		if err != nil {
			return nil, err
		}

		for constraintName, sql := range sqlUniqueConstraints {
			if !dbSchema.unique[constraintName] {
				ret = append(ret, sql)
			}
		}
		sqlIndexConstraints := dialect.GenerateIndexConstraintsSql(t)
		if err != nil {
			return nil, err
		}
		for constraintName, sql := range sqlIndexConstraints {
			if !dbSchema.index[constraintName] {
				ret = append(ret, sql)
			}

		}

	}
	return ret, nil
}
func (u *utilsPackage) DetectDatabaseType(db *sql.DB) (DBType, string, error) {
	var version string

	queries := []struct {
		query string
	}{
		{"SELECT version();"},        // PostgreSQL, MySQL, Cockroach, Greenplum
		{"SELECT @@VERSION;"},        // SQL Server, Sybase
		{"SELECT sqlite_version();"}, // SQLite
		{"SELECT tidb_version();"},   // TiDB
		{"SELECT * FROM v$version"},  // Oracle
	}

	for _, q := range queries {
		err := db.QueryRow(q.query).Scan(&version)
		if err == nil && version != "" {
			v := strings.ToLower(version)

			switch {
			case strings.Contains(v, "postgres"):
				if strings.Contains(v, "greenplum") {
					return DBGreenplum, version, nil
				}
				return DBPostgres, version, nil
			case strings.Contains(v, "cockroach"):
				return DBCockroach, version, nil
			case strings.Contains(v, "mysql"):
				if strings.Contains(v, "mariadb") {
					return DBMariaDB, version, nil
				}
				return DBMySQL, version, nil
			case strings.Contains(v, "mariadb"):
				return DBMariaDB, version, nil
			case strings.Contains(v, "microsoft") || strings.Contains(v, "sql server"):
				return DBMSSQL, version, nil
			case strings.Contains(v, "sqlite"):
				return DBSQLite, version, nil
			case strings.Contains(v, "tidb"):
				return DBTiDB, version, nil
			case strings.Contains(v, "oracle"):
				return DBOracle, version, nil
			}
		}
	}

	return DBUnknown, version, errors.New("unable to detect database type")
}
func (u *utilsPackage) GetCurrentDatabaseName(db *sql.DB, dbType DBType) (string, error) {
	var query string
	var dbName string

	switch dbType {
	case DBPostgres, DBGreenplum, DBCockroach:
		query = "SELECT current_database();"
	case DBMySQL, DBMariaDB, DBTiDB:
		query = "SELECT DATABASE();"
	case DBMSSQL:
		query = "SELECT DB_NAME();"
	case DBSQLite:
		query = "PRAGMA database_list;" // SQLite đặc biệt hơn, xem dưới
	case DBOracle:
		query = "SELECT SYS_CONTEXT('USERENV','DB_NAME') FROM dual;"
	default:
		return "", fmt.Errorf("unsupported db type: %s", dbType)
	}

	if dbType == DBSQLite {
		type sqliteEntry struct {
			Seq  int
			Name string
			File string
		}
		rows, err := db.Query(query)
		if err != nil {
			return "", err
		}
		defer rows.Close()

		for rows.Next() {
			var entry sqliteEntry
			if err := rows.Scan(&entry.Seq, &entry.Name, &entry.File); err != nil {
				return "", err
			}
			if entry.Seq == 0 {
				return entry.Name, nil // thường là "main"
			}
		}
		return "", fmt.Errorf("no database found in sqlite PRAGMA list")
	}

	// Các DB bình thường chỉ cần query trả 1 giá trị
	err := db.QueryRow(query).Scan(&dbName)
	if err != nil {
		return "", err
	}

	return dbName, nil
}
func (u *utilsPackage) GetDbName(db *sql.DB) (string, error) {
	dbType, _, err := u.DetectDatabaseType(db)
	if err != nil {
		return "", err
	}
	return u.GetCurrentDatabaseName(db, dbType)
}

func (u *utilsPackage) getTenantDb(db *sql.DB, typ reflect.Type) (*TenantDb, error) {
	dbType, dbName, err := u.DetectDatabaseType(db)
	if err != nil {
		return nil, err
	}
	key := fmt.Sprintf("%s_%s", dbType, dbName)
	//check from cache
	if val, ok := u.cacheGetTenantDb.Load(key); ok {
		return val.(*TenantDb), nil

	}

	for i := 0; i < typ.NumField(); i++ {
		field := typ.Field(i)
		if !field.Anonymous {
			continue
		}
		var baseType reflect.Type
		if field.Type.Kind() == reflect.Ptr {
			baseType = reflect.TypeOf(&TenantDb{})
		} else {
			baseType = reflect.TypeOf(TenantDb{})
		}
		if baseType.String() == field.Type.String() {
			_dbSchema, err := u.newTenantDb(db)
			if err != nil {
				return nil, err
			}
			u.cacheGetTenantDb.Store(key, _dbSchema)
			return _dbSchema, nil

		} else {
			_dbSchema, err := u.getTenantDb(db, field.Type)
			if err != nil {
				return nil, err
			} else if _dbSchema != nil {
				u.cacheGetTenantDb.Store(key, _dbSchema)
				return _dbSchema, nil
			} else {
				continue
			}
		}
	}
	return nil, nil
}
func (u *utilsPackage) newTenantDb(db *sql.DB) (*TenantDb, error) {
	ret := &TenantDb{}
	ret.DB = *db
	dbDetect, dbTypeName, err := utils.DetectDatabaseType(db)

	if err != nil {
		return nil, err
	}
	dbName, err := utils.GetCurrentDatabaseName(db, dbDetect)
	if err != nil {
		return nil, err
	}
	ret.DbName = dbName
	if dbDetect == DBMSSQL {
		ret.Dialect = NewSqlServerDialect()
		ret.DBType = DBMSSQL
		ret.DBTypeName = dbTypeName
	} else if dbDetect == DBMySQL {
		ret.Dialect = NewSqlServerDialect()
		ret.DBType = DBMySQL
		ret.DBTypeName = dbTypeName
	} else if dbDetect == DBPostgres {
		ret.DBType = DBPostgres
		ret.DBTypeName = dbTypeName
	} else {
		return nil, fmt.Errorf("Unsupported database type '%s'", dbTypeName)

	}
	return ret, nil
}

/*
This struct is only used for the function buildRepositoryFromType of the "utilsPackage"
*/
type repositoryValueStruct struct {
	/*
		The buildRepositoryFromType function of utilsPackage
		will analyze the type of repo: During the analysis process,
		it will use reflect.New(type) to create a value for this field
	*/
	ValueOfRepo    reflect.Value
	PtrValueOfRepo reflect.Value
	/*
		During the analysis of the entity type, these are fields that have struct types,
		and those structs have fields declared with types like DbField[<type>], including in embedded struct
	*/
	EntityTypes []reflect.Type
}

/*
This function will read information from @typ and create a structure similar to the one described in
"repositoryValueStruct" if no error occurs
*/
func (u *utilsPackage) buildRepositoryFromType(typ reflect.Type) (*repositoryValueStruct, error) {

	retValueOfRepo := reflect.New(typ)
	valueOfRepo := retValueOfRepo.Elem()

	baseType := reflect.TypeOf(TenantDb{})
	entityTypes := []reflect.Type{}
	for i := 0; i < typ.NumField(); i++ {

		field := typ.Field(i)
		fieldType := field.Type
		if field.Anonymous {
			if fieldType.Kind() == reflect.Ptr {
				fieldType = fieldType.Elem()
			}

			if baseType.Name() == fieldType.Name() {

				continue

			} else {
				repoVal, err := u.buildRepositoryFromType(field.Type) //<-- do not gen sql migrate for inner entity
				if err != nil {
					return nil, err
				}
				entityTypes = append(entityTypes, repoVal.EntityTypes...)
				valueOfRepo.Field(i).Set(repoVal.ValueOfRepo.Addr())
				// entityType := field.Type
				// if entityType.Kind() == reflect.Ptr {
				// 	entityType = entityType.Elem()
				// }

				continue
			}
		}
		if fieldType.Kind() == reflect.Ptr {
			fieldType = fieldType.Elem()
		}

		queryableVal := entityUtils.QueryableFromType(fieldType, utils.TableNameFromStruct(fieldType))
		queryableValField := valueOfRepo.Field(i)

		queryableValField.Set(queryableVal)

		entityType := field.Type
		if entityType.Kind() == reflect.Ptr {
			entityType = entityType.Elem()
		}
		entityTypes = append(entityTypes, entityType)
	}
	ret := &repositoryValueStruct{
		ValueOfRepo:    valueOfRepo,
		PtrValueOfRepo: retValueOfRepo,
		EntityTypes:    entityTypes,
	}
	return ret, nil
}

func (u *utilsPackage) GetOrCreateRepository(typ reflect.Type) (*repositoryValueStruct, error) {
	//check cache
	key := typ.String()
	if val, ok := u.cacheGetOrCreateRepository.Load(key); ok {
		return val.(*repositoryValueStruct), nil
	}
	repoVal, err := u.buildRepositoryFromType(typ)
	if err != nil {
		return nil, err
	}
	u.cacheGetOrCreateRepository.Store(key, repoVal)
	return repoVal, nil
}

func (u *utilsPackage) exprToSQLDelete(v interface{}, d Dialect) (string, []interface{}) {

	switch val := v.(type) {
	case *Field[any]:
		return val.ToSqlExpr(d)
	case *Field[string]:
		return val.ToSqlExpr(d)
	case *Field[int]:
		return val.ToSqlExpr(d)
	case *Field[float64]:
		return val.ToSqlExpr(d)
	case *Field[float32]:
		return val.ToSqlExpr(d)
	case *Field[uint64]:
		return val.ToSqlExpr(d)
	case *Field[bool]:
		return val.ToSqlExpr(d)
	default:
		return "?", []interface{}{val}
	}
}
func (u *utilsPackage) Join(parts []string, sep string) string {
	return u.join(parts, sep)
}
func (u *utilsPackage) join(parts []string, sep string) string {
	out := ""
	for i, p := range parts {
		if i > 0 {
			out += sep
		}
		out += p
	}
	return out
}
func (u *utilsPackage) PtrToInterface(v interface{}) interface{} {
	val := reflect.ValueOf(v)
	ptr := reflect.New(reflect.TypeOf((*interface{})(nil)).Elem()) // tạo interface{}
	ptr.Elem().Set(val)                                            // gán giá trị
	return ptr.Interface()                                         // trả *interface{}
}

type FieldMeta struct {
	Offset uintptr
	Typ    reflect.Type
}

func (u *utilsPackage) buildFieldMapNoCache(t reflect.Type) map[string]FieldMeta {
	m := map[string]FieldMeta{}
	fmt.Println(t.Kind())
	if t.Kind() == reflect.Ptr {
		t = t.Elem()
	}
	if t.Kind() == reflect.Slice {
		t = t.Elem()
	}
	if t.Kind() == reflect.Ptr {
		t = t.Elem()
	}
	for i := 0; i < t.NumField(); i++ {
		f := t.Field(i)
		if f.Anonymous {
			m2 := u.buildFieldMap(f.Type)
			for k, v := range m2 {
				m[k] = v
			}
		}
		m[f.Name] = FieldMeta{
			Offset: f.Offset,
			Typ:    f.Type,
		}
	}
	return m
}
func (u *utilsPackage) buildFieldMap(t reflect.Type) map[string]FieldMeta {
	if v, ok := u.cacheBuildFieldMap.Load(t); ok {
		return v.(map[string]FieldMeta)
	}
	m := u.buildFieldMapNoCache(t)
	u.cacheBuildFieldMap.Store(t, m)
	return m
}

// fastest fetchAllRows unsafe mode
func (u *utilsPackage) fetchAllRows(rows *sql.Rows, typ reflect.Type) (interface{}, error) {
	defer rows.Close()

	const defaultCap = 4096
	slice := reflect.MakeSlice(reflect.SliceOf(typ), 0, defaultCap)

	cols, err := rows.Columns()
	if err != nil {
		return nil, err
	}

	fieldMap := u.buildFieldMap(typ)

	for rows.Next() {
		ptr := reflect.New(typ)
		mem := unsafe.Pointer(ptr.Pointer()) // lấy địa chỉ trước khi gọi Elem
		val := ptr.Elem()

		scanArgs := make([]interface{}, len(cols))
		for i, col := range cols {
			if meta, ok := fieldMap[col]; ok {
				fieldPtr := unsafe.Pointer(uintptr(mem) + meta.Offset)

				switch meta.Typ.Kind() {
				case reflect.String:
					scanArgs[i] = (*string)(fieldPtr)
				case reflect.Int:
					scanArgs[i] = (*int)(fieldPtr)
				case reflect.Int64:
					scanArgs[i] = (*int64)(fieldPtr)
				case reflect.Float32:
					scanArgs[i] = (*float32)(fieldPtr)
				case reflect.Float64:
					scanArgs[i] = (*float64)(fieldPtr)
				case reflect.Bool:
					scanArgs[i] = (*bool)(fieldPtr)
				case reflect.Struct:
					// time.Time, uuid.UUID, etc.
					switch meta.Typ.String() {
					case "time.Time":
						scanArgs[i] = (*time.Time)(fieldPtr)
					case "uuid.UUID":
						scanArgs[i] = (*[16]byte)(fieldPtr) // hoặc dùng gorm UUID
					default:
						var dummy interface{}
						scanArgs[i] = &dummy
					}
				default:
					var dummy interface{}
					scanArgs[i] = &dummy
				}
			} else {
				var dummy interface{}
				scanArgs[i] = &dummy
			}
		}

		if err := rows.Scan(scanArgs...); err != nil {
			return nil, err
		}

		slice = reflect.Append(slice, val)
	}

	return slice.Interface(), nil
}
func (u *utilsPackage) getRequireFields(typ reflect.Type) map[string]FieldTag {
	//check cache
	if v, ok := u.cacheGetRequireFields.Load(typ.String()); ok {
		return v.(map[string]FieldTag)
	}
	tableMap := u.GetMetaInfo(typ)

	ret := make(map[string]FieldTag)
	for _, fields := range tableMap {
		for _, fieldTag := range fields {
			if (!fieldTag.AutoIncrement) && (!fieldTag.Nullable) && (fieldTag.Default == "") {
				ret[fieldTag.Field.Name] = fieldTag
			}
		}
	}
	u.cacheGetRequireFields.Store(typ.String(), ret)
	return ret

}
func (u *utilsPackage) getAutoPkKey(typ reflect.Type) *autoNumberKey {
	//check from cache
	if v, ok := u.cacheGetAutoPkKey.Load(typ.String()); ok {
		return v.(*autoNumberKey)
	}

	tableMap := u.GetMetaInfo(typ)
	for _, fields := range tableMap {
		for fieldName, fieldTag := range fields {
			if fieldTag.AutoIncrement {
				ret := &autoNumberKey{
					FieldName: fieldName,
					KeyType:   fieldTag.Field.Type,
					fieldTag:  &fieldTag,
				}
				u.cacheGetAutoPkKey.Store(typ.String(), ret)
				return ret
			}
		}
	}
	ret := &autoNumberKey{
		FieldName: "",
		KeyType:   nil,
	}
	u.cacheGetAutoPkKey.Store(typ.String(), ret)
	return ret
}

type autoNumberKey struct {
	FieldName string
	fieldTag  *FieldTag
	KeyType   reflect.Type
}

func (u *utilsPackage) extractValue(entityType reflect.Type, data interface{}) (*autoNumberKey, reflect.Type, map[string]interface{}, error) {
	ret := make(map[string]interface{})
	typ := reflect.TypeOf(data)
	valData := reflect.ValueOf(data)
	if typ.Kind() == reflect.Ptr {
		typ = typ.Elem()
		valData = valData.Elem()
	}
	tableMap := u.getRequireFields(entityType)
	for fieldName, fieldTag := range tableMap {
		fieldValue := valData.FieldByName(fieldName)
		if !fieldValue.IsValid() {
			dataFields := []string{}
			for i := 0; i < typ.NumField(); i++ {
				dataFields = append(dataFields, typ.Field(i).Name)
			}

			return nil, nil, nil, fmt.Errorf("%s is require but not found in %s/nFields: %s", fieldName, typ.String(), ToJsonString(dataFields))
		} else {
			val := fieldValue.Interface()
			if fieldTag.Length != nil {
				if fieldValue.Kind() == reflect.String {
					if len(val.(string)) == 0 {
						return nil, nil, nil, fmt.Errorf("%s is require but value is empty in %s/nFields: %s", fieldName, typ.String())
					}
					if len(val.(string)) > *fieldTag.Length {
						return nil, nil, nil, fmt.Errorf("size of '%s' in value of '%s' is exceed of %d", fieldName, typ.String(), *fieldTag.Length)
					}
				}

			}
			ret[fieldTag.Field.Name] = fieldValue.Interface()
		}

	}
	autoKey := u.getAutoPkKey(entityType)
	if autoKey.FieldName == "" {
		return nil, nil, ret, nil
	}
	if keyValueField, ok := typ.FieldByName(autoKey.fieldTag.Field.Name); ok {
		return autoKey, keyValueField.Type, ret, nil
	}
	return nil, nil, ret, nil

}

var utils = &utilsPackage{
	currentPackagePath: reflect.TypeOf(utilsPackage{}).PkgPath(),
	mapType: map[reflect.Type]string{
		reflect.TypeOf(FieldBigInt{}): "int64",
		reflect.TypeOf(FieldInt{}):    "int",
		reflect.TypeOf(FieldFloat{}):  "float64",
		reflect.TypeOf(FieldString{}): "string",
		reflect.TypeOf(FieldBool{}):   "bool",

		reflect.TypeOf(FieldUUID{}):     "uuid.UUID",
		reflect.TypeOf(FieldInt16{}):    "int16",
		reflect.TypeOf(FieldInt32{}):    "int32",
		reflect.TypeOf(FieldInt64{}):    "int64",
		reflect.TypeOf(FieldUint{}):     "uint",
		reflect.TypeOf(FieldUint16{}):   "uint16",
		reflect.TypeOf(FieldUint32{}):   "uint32",
		reflect.TypeOf(FieldUint64{}):   "uint64",
		reflect.TypeOf(FieldDateTime{}): "time.Time",
	},
}

func ToJsonString(data interface{}) string {
	jsonData, err := json.MarshalIndent(data, "", "  ")
	if err != nil {
		return ""
	}
	return string(jsonData)
}
func PrintJson(data interface{}) {
	fmt.Println(ToJsonString(data))
}
func GetRows[T any](cmd interface{}) ([]T, error) {
	if selectQr, ok := cmd.(*SelectQuery); ok {
		typ := reflect.TypeFor[T]()

		ret, err := selectQr.execToByType(typ)
		if err != nil {
			return nil, err
		}
		return ret.([]T), nil
	}
	if selectQr, ok := cmd.(*SelectQueryWithOrder); ok {
		typ := reflect.TypeFor[T]()

		ret, err := selectQr.execToByType(typ)
		if err != nil {
			return nil, err
		}
		return ret.([]T), nil
	}
	return nil, fmt.Errorf("%s must be *SelectQuery or *SelectQueryWithOrder", cmd)
}
